% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ensemble.R
\name{ensemble}
\alias{ensemble}
\title{Estimating Ensemble Kernel Matrices}
\usage{
ensemble(formula, label_names, Kernlist, data, mode, strategy, beta, lambda)
}
\arguments{
\item{formula}{A symbolic description of the model to be fitted.}

\item{label_names}{A character string indicating all the interior variables
included in each predictor.}

\item{Kernlist}{The kernel library containing several kernels given by user.}

\item{data}{A dataframe to be fitted.}

\item{mode}{A character string indicating which tuning parameter criteria is
to be used.}

\item{strategy}{A character string indicating which ensemble strategy is to
be used.}

\item{beta}{A numeric value specifying the parameter when strategy = "exp".}

\item{lambda}{A numeric string specifying the range of noise to be chosen.
The lower limit of lambda must be above 0.}
}
\value{
\item{lam}{The selected tuning parameter based on the estimated
ensemble kernel matrix.}

\item{intercept}{Estimated bias of the model.}

\item{alpha}{Estimated coefficients of the estimated ensemble kernel
matrix.}

\item{K}{Estimated ensemble kernel matrix.}

\item{u_hat}{A vector of weights of the kernels in the library.}
}
\description{
Conduct gaussian process regression based on the estimated ensemble kernel
matrix.
}
\details{
There are three ensemble strategies available here:

\bold{Empirical Risk Minimization}

After obtaining the estimated errors \eqn{\{\hat{\epsilon}_d\}_{d=1}^D}, we
estimate the ensemble weights \eqn{u=\{u_d\}_{d=1}^D} such that it minimizes
the overall error \deqn{\hat{u}=\underset{u \in \Delta}{argmin}\parallel
\sum_{d=1}^Du_d\hat{\epsilon}_d\parallel^2 \quad where\; \Delta=\{u | u \geq
0, \parallel u \parallel_1=1\}} Then produce the final ensemble prediction:
\deqn{\hat{h}=\sum_{d=1}^D \hat{u}_d h_d=\sum_{d=1}^D \hat{u}_d
A_{d,\hat{\lambda}_d}y=\hat{A}y} where \eqn{\hat{A}=\sum_{d=1}^D \hat{u}_d
A_{d,\hat{\lambda}_d}} is the ensemble matrix.

\bold{Simple Averaging}

Motivated by existing literature in omnibus kernel, we propose another way
to obtain the ensemble matrix by simply choosing unsupervised weights
\eqn{u_d=1/D} for \eqn{d=1,2,...D}.

\bold{Exponential Weighting}

Additionally, another scholar gives a new strategy to calculate weights
based on the estimated errors \eqn{\{\hat{\epsilon}_d\}_{d=1}^D}.
\deqn{u_d(\beta)=\frac{exp(-\parallel \hat{\epsilon}_d
\parallel_2^2/\beta)}{\sum_{d=1}^Dexp(-\parallel \hat{\epsilon}_d
\parallel_2^2/\beta)}}

Then we can calculate the outpur of gaussian process regression, the
solution is given by \deqn{\hat{\beta}=[1^T(K+\lambda
I)^{-1}1]^{-1}1^T(K+\lambda I)^{-1}y} \deqn{\hat{\alpha}=(K+\lambda
I)^{-1}(y-\hat{\beta}1)} where \eqn{\beta=intercept}.
}
\examples{

##ensemble(formula = Y ~ X1 + X2,
##label_names = list(X1 = c("x1", "x2"), X2 = c("x3", "x4")),
##Kernlist = Kernlist, data = data, mode = "loocv",
##strategy = "erm", beta = 1, lambda = exp(seq(-5, 5)))

}
\references{
Jeremiah Zhe Liu and Brent Coull. Robust Hypothesis Test for
Nonlinear Effect with Gaus- sian Processes. October 2017.

Xiang Zhan, Anna Plantinga, Ni Zhao, and Michael C. Wu. A fast small-sample
kernel inde- pendence test for microbiome community-level association
analysis. December 2017.

Arnak S. Dalalyan and Alexandre B. Tsybakov. Aggregation by Exponential
Weighting and Sharp Oracle Inequalities. In Learning Theory, Lecture Notes
in Computer Science, pages 97â€“ 111. Springer, Berlin, Heidelberg, June 2007.
}
\author{
Wenying Deng
}
